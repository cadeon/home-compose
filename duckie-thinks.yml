version: '3.8'

services:
  app:
    image: cadeon924/duckiesays:duckie-thinks
    ports:
      - "3000:3000" # Map host port 3000 to container port 3000
    volumes:
      - ./log:/usr/src/app/log # Persist logs
    environment:
      NODE_ENV: development # Set Node.js environment to development
      OLLAMA_API_URL: http://172.31.250.200:11434/api/generate # Ollama API URL
      OLLAMA_MODEL: qwen2.5:0.5b # Ollama model
    networks:
      - traefik-public
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.duckiethinks.entrypoints=websecure"
      - "traefik.http.routers.duckiethinks.tls.certresolver=letsencrypt"
      - "traefik.http.routers.duckiethinks.tls.domains[0].main=duckiesays.com"
      - "traefik.http.routers.duckiethinks.tls.domains[0].sans=*.duckiesays.com,duckiesays.not-really.me"
      - "traefik.http.routers.duckiethinks.rule=HostRegexp(`duckiesays.com|duckiesays.not-really.me`)"
      - "traefik.http.services.duckiethinks.loadbalancer.server.port=3000"
      - "traefik.docker.network=traefik-public"
    depends_on:
      - ollama # Ensure ollama starts before the app

  ollama:
    image: ollama/ollama:latest # Use the latest Ollama image
    environment:
      - OLLAMA_KEEP_ALIVE=-1
    ports:
      - "11434:11434" # Expose Ollama port
    networks:
      - traefik-public
    volumes:
      - ollama_data:/root/.ollama # Persist Ollama data

networks:
  traefik-public:
    external: true
    driver: bridge
volumes:
  ollama_data: # Define a volume for Ollama data